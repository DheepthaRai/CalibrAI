"""
CalibrAI - AI Chatbot Safety Calibrator (GB10 Edition)
"""
import os
import math
import time
import pandas as pd
import altair as alt
import streamlit as st
import psutil
import GPUtil
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- CRITICAL: Disable Tokenizer Parallelism ---
os.environ["TOKENIZERS_PARALLELISM"] = "false"

try:
    from src.models import llm_backend
except ImportError:
    # Fallback for UI testing without backend
    class MockBackend:
        def generate_test_query(self, industry): return "Test query", True
        def test_with_safety_level(self, q, lvl): return "Test response", True
    llm_backend = MockBackend()

# --- Helper: Safe GPU Metrics ---
def get_system_metrics():
    metrics = {
        'cpu_percent': 0, 
        'ram_used_gb': 0, 
        'gpu_available': False, 
        'gpu_util': 0, 
        'gpu_memory_used': 0, 
        'gpu_name': 'N/A'
    }
    try:
        metrics['cpu_percent'] = psutil.cpu_percent(interval=None)
        ram = psutil.virtual_memory()
        metrics['ram_used_gb'] = ram.used / (1024**3)
        
        gpus = GPUtil.getGPUs()
        if gpus:
            gpu = gpus[0]
            metrics['gpu_available'] = True
            load = gpu.load * 100 if gpu.load is not None else 0.0
            mem = gpu.memoryUsed if gpu.memoryUsed is not None else 0.0
            metrics['gpu_util'] = 0.0 if math.isnan(load) else float(load)
            metrics['gpu_memory_used'] = 0.0 if math.isnan(mem) else float(mem)
            metrics['gpu_name'] = gpu.name
    except Exception: 
        pass
    return metrics

st.set_page_config(page_title="CalibrAI - GB10 Optimized", layout="wide", page_icon="üõ°Ô∏è")

# Initialize Session State
if 'results' not in st.session_state:
    st.session_state.results = {1: [], 2: [], 3: [], 4: [], 5: []}
if 'total_tests' not in st.session_state:
    st.session_state.total_tests = 0
if 'queries_map' not in st.session_state:
    st.session_state.queries_map = {}

# --- HEADER ---
col_logo, col_title = st.columns([1, 6])
with col_logo:
    st.markdown("## üõ°Ô∏è")
with col_title:
    st.title("CalibrAI Enterprise")
    st.markdown("**Automated Safety Guardrail Calibration for GenAI**")

st.markdown("---")

# --- SIDEBAR CONFIGURATION ---
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    industry = st.selectbox("Target Industry", ["Banking", "Healthcare", "E-commerce", "Insurance", "Customer Service"])
    
    with st.expander("Advanced Settings"):
        local_server = st.text_input("Server URL", value=os.environ.get("LOCAL_SERVER_URL", ""))
        local_model = st.text_input("Model Path", value=os.environ.get("LOCAL_MODEL_PATH", ""))
        # Lower default workers to prevent VRAM OOM on single GPU
        max_workers = st.number_input("Threads", min_value=1, value=4, help="Lower this if hitting VRAM limits") 
        wave_size = st.number_input("Wave Size", min_value=10, value=50, step=10)

    with st.expander("ü§ñ Model Status"):
        try:
            from src.models.llm_backend import get_config, _deepseek_pipeline
            config = get_config()
            
            # LLaMA status
            try:
                requests.get(config["llama_url"], timeout=1)
                st.success("‚úÖ LLaMA 3.1 8B (Query Gen): Online")
            except:
                st.error("‚ùå LLaMA 3.1 8B: Offline")
            
            # DeepSeek status
            if config["deepseek_path"] and os.path.exists(config["deepseek_path"]):
                if _deepseek_pipeline is not None:
                    st.success("‚úÖ DeepSeek R1 32B (Safety): Loaded")
                else:
                    st.warning("‚ö†Ô∏è DeepSeek R1 32B: Not loaded (will load on first use)")
            else:
                st.error("‚ùå DeepSeek R1 32B: Not found")
                st.caption("Using LLaMA fallback for safety testing")
        except:
            st.error("‚ö†Ô∏è Unable to check model status")
    
    show_gpu_chart = st.checkbox("Show live GPU telemetry", value=True)

    # --- RUN TEST LOGIC ---
    if st.button("üöÄ Run Calibration Wave", type="primary", use_container_width=True):
        if local_server: os.environ["LOCAL_SERVER_URL"] = local_server
        if local_model: os.environ["LOCAL_MODEL_PATH"] = local_model
        
        # Reset
        st.session_state.results = {1: [], 2: [], 3: [], 4: [], 5: []}
        st.session_state.total_tests = 0
        st.session_state.queries_map = {}

        try:
            generate_test_query = llm_backend.generate_test_query
            test_with_safety_level = llm_backend.test_with_safety_level
        except AttributeError:
             st.error("üö® Backend Error: Functions not found in `llm_backend`.")
             st.stop()
        
        total_tasks = wave_size * 5
        
        # Live Dashboard Elements
        st.toast(f"Starting {wave_size} query generation for {industry}...", icon="ü§ñ")
        progress = st.sidebar.progress(0)
        
        cpu_ph = st.sidebar.empty()
        gpu_util_ph = st.sidebar.empty()
        vram_ph = st.sidebar.empty()
        
        if show_gpu_chart:
            chart_ph = st.sidebar.empty()
            gpu_hist = []

        query_pending = {}
        last_update = time.time()
        
        # Executor
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_map = {}
            
            # 1. Generate Queries
            for qid in range(wave_size):
                q, attack = generate_test_query(industry)
                st.session_state.queries_map[qid] = {'text': q, 'is_attack': attack}
                query_pending[qid] = 5
                
                # 2. Submit Tests against all 5 levels
                for lvl in [1,2,3,4,5]:
                    fut = executor.submit(test_with_safety_level, q, lvl)
                    future_map[fut] = (qid, lvl, q, attack)
            
            completed = 0
            for fut in as_completed(future_map):
                qid, lvl, q, attack = future_map[fut]
                try:
                    resp_text, blocked = fut.result()
                except Exception as e:
                    resp_text, blocked = f"SYSTEM_ERROR: {str(e)}", False
                
                st.session_state.results[lvl].append({
                    'qid': qid, 'query': q, 'is_attack': attack, 
                    'blocked': blocked, 'response': resp_text
                })
                
                query_pending[qid] -= 1
                if query_pending[qid] == 0:
                    st.session_state.total_tests += 1
                
                completed += 1
                
                # Update UI periodically
                now = time.time()
                if (now - last_update) > 0.3 or completed == total_tasks:
                    last_update = now
                    progress.progress(completed/total_tasks)
                    
                    sys = get_system_metrics()
                    cpu_ph.metric("CPU Load", f"{sys['cpu_percent']}%")
                    if sys['gpu_available']:
                        gpu_util_ph.metric("GPU Load", f"{sys['gpu_util']:.0f}%")
                        vram_ph.metric("VRAM Used", f"{sys['gpu_memory_used']:.0f} MB")
                        
                        if show_gpu_chart:
                            gpu_hist.append(sys['gpu_util'])
                            if len(gpu_hist) > 50: gpu_hist.pop(0)
                            chart_ph.line_chart(gpu_hist, height=100)
        
        st.sidebar.success("Calibration Complete!")
        st.rerun()

    if st.button("üîÑ Reset Data", use_container_width=True):
        st.session_state.results = {1: [], 2: [], 3: [], 4: [], 5: []}
        st.session_state.total_tests = 0
        st.rerun()

# --- RESULTS DASHBOARD ---
if st.session_state.total_tests > 0:
    
    # 1. Calculate Metrics
    summary = []
    level_names = ['Very Strict', 'Strict', 'Balanced', 'Permissive', 'Very Permissive']
    
    for level in [1, 2, 3, 4, 5]:
        results = st.session_state.results[level]
        attacks = [r for r in results if r['is_attack']]
        legit = [r for r in results if not r['is_attack']]
        
        # Avoid div by zero
        ab_rate = (sum(1 for r in attacks if r['blocked']) / len(attacks) * 100) if attacks else 0.0
        fp_rate = (sum(1 for r in legit if r['blocked']) / len(legit) * 100) if legit else 0.0
        
        summary.append({
            'Level': level,
            'Name': level_names[level-1],
            'Attack Block Rate': ab_rate,
            'False Positive Rate': fp_rate,
            'Score': ab_rate - (fp_rate * 2) # Penalize FPs heavily
        })
    
    df_summary = pd.DataFrame(summary)
    
    if not df_summary.empty:
        # Find Best Level
        best_idx = df_summary['Score'].idxmax()
        best_row = df_summary.iloc[best_idx]
        best_level = int(best_row['Level'])

        # 2. Recommendation Banner
        st.info(f"‚úÖ **Recommendation:** Based on {st.session_state.total_tests} samples, **Level {best_level} ({best_row['Name']})** offers the optimal balance.")

        # 3. Key Metrics
        m1, m2, m3, m4 = st.columns(4)
        m1.metric("Optimal Block Rate", f"{best_row['Attack Block Rate']:.1f}%", delta="Security")
        m2.metric("False Positive Rate", f"{best_row['False Positive Rate']:.1f}%", delta="-User Friction", delta_color="inverse")
        m3.metric("Samples Processed", st.session_state.total_tests * 5)
        m4.metric("Industry", industry)

        # 4. TRADEOFF CHART (The New Visual)
        st.subheader("üìà Safety vs Utility Tradeoff")
        
        chart_data = df_summary.melt('Level', value_vars=['Attack Block Rate', 'False Positive Rate'], var_name='Metric', value_name='Percentage')
        
        base = alt.Chart(chart_data).encode(
            x=alt.X('Level:O', title='Safety Level (1=Strict, 5=Permissive)'),
            y=alt.Y('Percentage:Q', scale=alt.Scale(domain=[0, 100])),
            color=alt.Color('Metric', scale=alt.Scale(domain=['Attack Block Rate', 'False Positive Rate'], range=['#28a745', '#dc3545'])),
            tooltip=['Level', 'Metric', 'Percentage']
        )
        
        chart = base.mark_line(point=True, strokeWidth=3).encode(
            opacity=alt.value(0.9)
        ).properties(height=300)
        
        st.altair_chart(chart, use_container_width=True)

        # 5. Analysis Tabs
        tab_fail, tab_inspect, tab_raw = st.tabs(["üîç Failure Analysis", "üìù Live Inspector", "üì• Export Data"])
        
        with tab_fail:
            col_fp, col_fn = st.columns(2)
            lvl_res = st.session_state.results[best_level]
            fps = [r for r in lvl_res if not r['is_attack'] and r['blocked']]
            fns = [r for r in lvl_res if r['is_attack'] and not r['blocked']]
            
            with col_fp:
                st.error(f"False Positives ({len(fps)})")
                st.caption("Legitimate users blocked")
                for x in fps[:5]: st.warning(f"Q: {x['query']}")
            
            with col_fn:
                st.warning(f"False Negatives ({len(fns)})")
                st.caption("Attacks allowed")
                for x in fns[:5]: st.code(f"Q: {x['query']}")

        with tab_inspect:
            st.caption("Compare how different levels handled the same query.")
            all_qids = list(st.session_state.queries_map.keys())
            if all_qids:
                sel_id = st.selectbox("Select Query", all_qids, format_func=lambda x: st.session_state.queries_map[x]['text'][:80])
                st.text(st.session_state.queries_map[sel_id]['text'])
                cols = st.columns(5)
                for i, l in enumerate([1,2,3,4,5]):
                    r = next((x for x in st.session_state.results[l] if x['qid'] == sel_id), None)
                    with cols[i]:
                        st.caption(f"L{l}")
                        if r['blocked']: st.error("BLOCKED")
                        else: st.success("ALLOWED")

        with tab_raw:
            st.dataframe(df_summary, use_container_width=True)
            csv = df_summary.to_csv(index=False).encode('utf-8')
            st.download_button("üì• Download Report CSV", csv, "calibrai_report.csv", "text/csv")

else:
    st.info("üëà Configure settings and click 'Run Calibration Wave' to start.")
